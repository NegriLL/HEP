Instructions for running the files and the answers of each exercise

Execute the following commands
    make
    bash test.job
    python3 analysis.py
outputs:
    GenData:
        signal.out : Pythia event output for the Drel-Yan Process with summary at the bottom
        noise.out : Pythia event output for the ttbar Process with summary at the bottom
        signal.root : Saved muon events for the Drel-Yan Process
        noise.root : Saved muon events for the ttbar process
    Graphs:
        Mass Distribution.png : Plotted and fitted mass distributions
    Terminal:
        Signal significance calculation

# Part 1
The production cross section of the Z boson is approximately 2.010nb for a muon muon decay
(source https://cds.cern.ch/record/2868001/files/SMP-22-017-pas.pdf)
The luminosity of the LHC is 88.9 fb-1 at the CMS
(https://home.cern/news/news/accelerators/accelerator-report-lhc-run-3-achieves-record-breaking-integrated-luminosity)
A quick calculation will give 1.778e-4, so at around 1 million events we will see about 178 Z bosons, which is a good start

The signal efficiency can be found at the bottom of the noise.out and signal.out. During my run the numbers were as follows:
Noise:
Number of events 1000000
Signal Muons: 229183
Signal Efficiency: 22.918%

Signal:
Number of events 1000000
Signal Muons: 22056
Signal Efficiency: 2.206%

# Part 2
The noise is about 560mb, so the integrated luminosity necessary for a 5 sigma signal is at least 118 fb
CMS would take approximately 6.5 months to reach such a luminosity
Source: https://twiki.cern.ch/twiki/bin/view/CMSPublic/LumiPublicResults#2024_proton_proton_collisions_at

# Part 3
The data is very clear about the existence of a peak at 91 GeV, and that is the prediction of the standard model. Considering that we have reached a very high sigma, we can confidently say that the measurement has statistical significance. I can certainly convince myself that, if this were real data, I would have found evidence for the existence of the Z Boson as predicted by the Standard Model. Regardless, I would still prefer to do further, more accurate analysis of the data to make sure there is absolutely no ambiguity in the results.

We could find a few ways to improve the experiment. We can always collect more data to refine our results. We could account for further corrections in the muon path such as photon emmission. It would be good to simulate the detectors more accurately using GEANT for example, and add physically simulated errors. It would also be important to propagate those errors to our final data, so we can get a better idea of the mass range we are working with.
Lastly, it would be important to simulate other events that generate muons in the background besides ttbar. That way we can make sure that our signal efficiency in our simulation is not a fluke.

# Explaining non trivial choices
I chose to create two root files because the number of signal and background events might be unequal. I could have made an additional boolean branch to distinguish events and save them in a single Tree, but I thought that it would be better to do things separately and run them concurrently through the command line rather than using a mutex.
The change from tcsh to bash in the test.job file happened because ROOT was not working properly on my Clubbi Linux machine. Invoking the ROOT::Fit() function would give me a segmentation fault. I could not find the root cause (pun intended), so I installed the dependencies on my personal computer where bash was more frictionless to use.
